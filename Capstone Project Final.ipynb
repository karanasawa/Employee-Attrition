{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b977eec",
   "metadata": {},
   "source": [
    "## TITLE :- Employee Attrition Analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26557a23",
   "metadata": {},
   "source": [
    "### Problem Statement :- Based on department data and employee data regarding administrative, work-load and mutual evaluation score predict whether an employee will stay or leave . \n",
    "\n",
    "* The target variable in our project is \"ATTRITION\"\n",
    "\n",
    "* Attrition refers to the gradual but deliberate reduction in staff that occurs as employees leave a company and aren't replaced. Employees may leave voluntarily or involuntarily.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9bb542",
   "metadata": {},
   "source": [
    "# Importing necessary libraries:- \n",
    "\n",
    "* warnings - Importing the warnings module to handle any warning messages\n",
    "* warnings.filterwarnings - Ignoring any warning messages that might occur during the execution of the code \n",
    "* numpy - To perform statistical functions with the data\n",
    "* pandas - To perform Exploratory Data Analysis for the dataset\n",
    "* matplotlib and seaborn - To visualise critical attributes of the dataset and to represent graphical representation of same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4523d9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcba8ad9",
   "metadata": {},
   "source": [
    "# Description of features\n",
    "#### 1 Age -Employee's age\n",
    "#### 2 Gender-Employee's Gender\n",
    "#### 3 BusinessTravel\t-Frequency of employees' business trips\n",
    "#### 4 DailyRate\tDaily -salary rate for employees\n",
    "#### 5 Department-Office of employees\n",
    "#### 6 DistanceFromHome-Distance from home in miles to work\n",
    "#### 7 Education-Level of education achieved by staff\n",
    "#### 8 EducationField-Employee's field of study\n",
    "#### 9 EmployeeCount-Total number of employees in the organization\n",
    "#### 10 EmployeeNumber-A unique identifier for each employee record\n",
    "#### 11 EnvironmentSatisfaction\t-Employee satisfaction with their working environment\n",
    "#### 12 HourlyRate-Hourly rate for employees\n",
    "#### 13 JobInvolvement-Level of involvement required for the employee's job\n",
    "#### 14 JobLevel-Employee's level of work\n",
    "#### 15 JobRole-The role of employees in the organization\n",
    "#### 16 JobSatisfaction-Employee satisfaction with their work\n",
    "#### 17 MaritalStatus-Employee's marital status\n",
    "#### 18 MonthlyIncome-Employee's monthly income\n",
    "#### 19 MonthlyRate-Monthly salary rate for employees\n",
    "#### 20 NumCompaniesWorked-Number of companies the employee worked for\n",
    "#### 21 Over18-Whether the employee is over 18 years old\n",
    "#### 22 OverTime-Do employees work overtime\n",
    "#### 23 PercentSalaryHike-Salary increase rate for employees\n",
    "#### 24 PerformanceRating-The performance rating of the employee\n",
    "#### 25 RelationshipSatisfaction-Employee satisfaction with their relationships\n",
    "#### 26 StandardHours-Standard working hours for employees\n",
    "#### 27 StockOptionLevel-Employee stock option level\n",
    "#### 28 TotalWorkingYears-Total number of years the employee has worked\n",
    "#### 29 TrainingTimesLastYear-Number of times employees were taken to training in the last year\n",
    "#### 30 WorkLifeBalance-Employees' perception of their work-life balance\n",
    "#### 31 YearsAtCompany-Number of years employees have been with the company\n",
    "#### 32 YearsInCurrentRole-Number of years the employee has been in their current role\n",
    "#### 33 YearsSinceLastPromotion-Number of years since employee's last promotion\n",
    "#### 34 YearsWithCurrManager-Number of years an employee has been with their current manager\n",
    "#### 35 Attrition-Does the employee leave the organization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a10d954",
   "metadata": {},
   "source": [
    "# Generic Process of Exploratory Data Analysis \n",
    "\n",
    "\n",
    "1. Import file -- excel file, csv file (data set)\n",
    "\n",
    "\n",
    "2. To check the dataframe \n",
    "    * Number of features - rows and columns\n",
    "    * To check top 5 rows\n",
    "    * To check the bottom five rows\n",
    "    * Check duplicates-- if there are any duplicates drop them\n",
    "    \n",
    "\n",
    "3. Check the shape of the dataframe -- Total No of rows and No of columns are there in a dataset\n",
    "\n",
    "\n",
    "4. To check the info of the dataset --> If the columns of dataset are empty or not along with their data type\n",
    "\n",
    "\n",
    "5. To check the null values and duplicates within the dataset.\n",
    "\n",
    "\n",
    "6. If there are null values in the dataset and if present then treat them\n",
    "\n",
    "     * continuous variable --  mean, median,b-fill,f-fill\n",
    "     * categorical variable --  mode\n",
    "    \n",
    "    \n",
    "7. The statistical information of the dataset\n",
    "\n",
    "\n",
    "8. Data Visualization --> finding the insights from the data graphically\n",
    "\n",
    "      PLOTS\n",
    "      \n",
    "    a) one continuous variable -- Box plot, histogram\n",
    "    \n",
    "    b) one categorical variable -- value_counts, countplots\n",
    "    \n",
    "    c) one continuous variable and one categorical variable -- Box plot, Bar plot\n",
    "    \n",
    "    d) Two continuous variable -- scatter plot\n",
    "    \n",
    "    e) Two categorical variable and one continuous variable -- Barplot\n",
    "    \n",
    "    f) pairplot - We plot both for categorical and  continuous \n",
    "    \n",
    "    g) Heatmaps - To represent the collinearity between all the attributes  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a756954d",
   "metadata": {},
   "source": [
    "## Importing dataset in variable 'df' and printing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff4cfeeb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/shrut/Desktop/Edubridge/IBM_DATASET.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:/Users/shrut/Desktop/Edubridge/IBM_DATASET.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m df\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/shrut/Desktop/Edubridge/IBM_DATASET.csv'"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/shrut/Desktop/Edubridge/IBM_DATASET.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bdbe8d",
   "metadata": {},
   "source": [
    "## Checking first five rows of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e998c928",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6994891",
   "metadata": {},
   "source": [
    "## Checking last five rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ee618b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca0279d",
   "metadata": {},
   "source": [
    "## Checking the shape of dataset -- the total number of rows and columns of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b6bd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b82170",
   "metadata": {},
   "source": [
    "## To check the datatype and count of non - null values in the data\n",
    "\n",
    " * For Continuous - int64 , float\n",
    " * For Categorical - object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa0aac0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae59f86",
   "metadata": {},
   "source": [
    "## Checking if there are duplicates in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3773cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e573513",
   "metadata": {},
   "source": [
    "## To check the statistical information for continuous variables of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f12908",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014f2637",
   "metadata": {},
   "source": [
    "## Checking if there are null (missing) values in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb317245",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c588d48",
   "metadata": {},
   "source": [
    "## Dropping redundant information/Columns which are insignificant to the target variable \"Attrition\":-\n",
    "\n",
    "Dropping columns : \"EmployeeCount\", \"EmployeeNumber\", \"Over18\", \"StandardHours\"\n",
    "\n",
    "* EmployeeCount - It is '1' for all \n",
    "* EmployeeNumber- S no 1 to 1470\n",
    "* Over18 - Y for all\n",
    "* StandardHours - 80 for all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d0a32f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#If we have to permanent drop just give inplace =True, axis=1 (for Column)\n",
    "df.drop([\"EmployeeCount\",\"EmployeeNumber\",\"Over18\",\"StandardHours\"],inplace =True ,axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d825499",
   "metadata": {},
   "source": [
    "## Checking all coulmn names in the data after dropping the redundant coulms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baf85b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72e04ba",
   "metadata": {},
   "source": [
    "## To check the new shape of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a7f2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eda8a15",
   "metadata": {},
   "source": [
    "## To check unique values of in each attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be40f224",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for column in df.columns:\n",
    "    if df[column].dtype==object:\n",
    "        print(str(column)+':'+str(df[column].unique()))\n",
    "        print(df[column].value_counts())\n",
    "        print('_______________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05dbb86",
   "metadata": {},
   "source": [
    "## Performing pandas- profiling (also known as 1 line EDA) :-  It gives a report format of the EDA which we have performed step wise above on its own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff48168f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8466f6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a3b9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb7c7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = ProfileReport(df)\n",
    "pf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e140e5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pf.to_file(\"output.html\")\n",
    "pf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94f040e",
   "metadata": {},
   "source": [
    "# Visualisation of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727dcf50",
   "metadata": {},
   "source": [
    "## To see the number of continuous variables in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865407fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "continuous = df.select_dtypes('int').columns\n",
    "continuous"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f832599d",
   "metadata": {},
   "source": [
    "##### There are a few columns in this data which are categorical by nature but have already been label-encoded from before so they are converted into countinuous variables and being printed as same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acb27ab",
   "metadata": {},
   "source": [
    "## Plotting boxplot for all continuous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d5dedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in continuous:\n",
    "    sns.boxplot(x  = df[i],data=df,orient=\"h\") \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9aa4a2",
   "metadata": {},
   "source": [
    "#### It can be commented from the above plots, that there are at least 10 variables which seems to have Outliers present in them. But we will not consider them to be outliers as the information of these variables is very sensitive and subjectively valid for particular employee. Also another reason for not considering these values to be Outliers is that there has been no range specified in between which the values need to be cnosidered. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5606d66",
   "metadata": {},
   "source": [
    "## To see the number of categorical variables in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c08086",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "categorical = df.select_dtypes('object').columns\n",
    "categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00db1f2",
   "metadata": {},
   "source": [
    "## Plotting countplot for all categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b364fdf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in categorical:\n",
    "    sns.countplot(x  = df[i],data=df)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bda0b41",
   "metadata": {},
   "source": [
    "## DISTRIBUTION OF EMPLOYEE ATTRITION IN THE COMPANY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a035e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = 'Attrition NO','Attrition YES'\n",
    "df['Attrition'].astype(str).value_counts().plot(kind='pie',\n",
    "                            figsize=(15, 6),\n",
    "                            autopct='%1.1f%%', \n",
    "                            startangle=90,    \n",
    "                            shadow=True,       \n",
    "                            labels=None,                                \n",
    "                            )\n",
    "\n",
    "plt.title('Distribution of Employee Attrition in the Company ', y=1.12) \n",
    "plt.axis('equal') \n",
    "# add legend\n",
    "plt.legend(labels=labels, loc='upper left') \n",
    " # show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c998c0",
   "metadata": {},
   "source": [
    "### From the Pie Chart, we can infer that out of 1470 employees, 16.1% of the employees left their job due to some reasons whereas other 83.9% of the employees preferred to continue their job at the company."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2902561e",
   "metadata": {},
   "source": [
    "# Analysis of the Rating Features\n",
    "\n",
    "#### JobSatisfaction\n",
    "#### EnvironmentSatisfaction\n",
    "#### RelationshipSatisfaction\n",
    "#### JobInvolvement\n",
    "#### WorkLifeBalance\n",
    "#### PerformanceRating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f8732b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['JobSatisfaction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e083cd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure() \n",
    "\n",
    "ax1 = fig.add_subplot(221) \n",
    "ax2 = fig.add_subplot(222)  \n",
    "ax3 = fig.add_subplot(223) \n",
    "ax4 = fig.add_subplot(224)  \n",
    "\n",
    "labels = 'Low','Medium','High','Very High'\n",
    "\n",
    "df['JobSatisfaction'].astype(str).value_counts().plot(kind='pie',\n",
    "                            figsize=(15, 6),\n",
    "                            autopct='%1.1f%%', \n",
    "                            startangle=90,    \n",
    "                            shadow=True,       \n",
    "                            labels=None,ax=ax1) # add to subplot 2\n",
    "ax1.set_title ('Rating of Job Satisfaction by Employees')\n",
    "fig.legend(labels=labels,loc='center')\n",
    "\n",
    "df['EnvironmentSatisfaction'].astype(str).value_counts().plot(kind='pie',\n",
    "                            figsize=(15, 6),\n",
    "                            autopct='%1.1f%%', \n",
    "                            startangle=90,    \n",
    "                            shadow=True,       \n",
    "                            labels=None,ax=ax2) \n",
    "ax2.set_title('Rating of Environmental Satisfaction by Employees')\n",
    "df['RelationshipSatisfaction'].astype(str).value_counts().plot(kind='pie',\n",
    "                            figsize=(15, 6),\n",
    "                            autopct='%1.1f%%', \n",
    "                            startangle=90,    \n",
    "                            shadow=True,       \n",
    "                            labels=None,ax=ax3)\n",
    "ax3.set_title('Rating of Relationship Satisfaction by Employees')\n",
    "\n",
    "df['JobInvolvement'].astype(str).value_counts().plot(kind='pie',\n",
    "                            figsize=(15, 6),\n",
    "                            autopct='%1.1f%%', \n",
    "                            startangle=90,    \n",
    "                            shadow=True,       \n",
    "                            labels=None,ax=ax4) \n",
    "ax4.set_title('Rating of Job Involvement by Employees')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc95f42e",
   "metadata": {},
   "source": [
    "### From the subplot, we can infer that more than 60% of the employees are :\n",
    "\n",
    "* Not Satisfied in their Job\n",
    "* Not Satisfied with their Work Environmnet\n",
    "* Not Satisfied in their Relationship\n",
    "* Not Getting involved in their job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07a2ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = plt.figure() \n",
    "\n",
    "ax5 = fig2.add_subplot(121) \n",
    "ax6 = fig2.add_subplot(122)  \n",
    "  \n",
    "labels_list1 = 'Bad','Good','Better','Best' \n",
    "labels_list2 = 'Low','Good','Excellent','Outstanding'\n",
    "\n",
    "df['WorkLifeBalance'].astype(str).value_counts().plot(kind='pie',\n",
    "                            figsize=(15, 6),\n",
    "                            autopct='%1.1f%%', \n",
    "                            startangle=90,    \n",
    "                            shadow=True,       \n",
    "                            labels=None,ax=ax5) # add to subplot 2\n",
    "ax5.set_title ('Rating of Work-Life Balance by Employees')\n",
    "ax5.legend(labels=labels_list1,loc='upper right')\n",
    "\n",
    "df['PerformanceRating'].astype(str).value_counts().plot(kind='pie',\n",
    "                            figsize=(15, 6),\n",
    "                            autopct='%1.1f%%', \n",
    "                            startangle=90,    \n",
    "                            shadow=True,       \n",
    "                            labels=None,ax=ax6) \n",
    "ax6.set_title('Performance Rating of the Employees')\n",
    "ax6.legend(labels=labels_list2,loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77516737",
   "metadata": {},
   "source": [
    "### From the above piecharts, we can see that:\n",
    "\n",
    "* Almost 60% of the employees have rated their Work-life Balance as Bad\n",
    "* Almost 85% of the employees have a low performance rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086d6743",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "props = df.groupby(\"BusinessTravel\")['Attrition'].value_counts(normalize=False).unstack()\n",
    "\n",
    "props.plot(kind='bar', alpha=1, stacked='False')\n",
    "\n",
    "plt.title('Business Travel VS Attrition')\n",
    "plt.ylabel('Number of Employee')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581139bd",
   "metadata": {},
   "source": [
    "#### From the above data it is clear that Employees who travel rarely have more attrition rate followed by Employees who travel frequently\n",
    "\n",
    "#### Best way to reduce this attrition is to conduct monthly survey and to assign travel according to the Employees' business travel interest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb46c354",
   "metadata": {},
   "source": [
    "# Analysis of Work Experience\n",
    "### Years At Company\n",
    "### Years In CurrentRole\n",
    "### Years Since LastPromotion\n",
    "### Years With CurrManager\n",
    "### Total Working Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb71db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "yac = df.groupby(\"YearsAtCompany\")['Attrition'].value_counts(normalize=False).unstack()\n",
    "\n",
    "yac.plot(kind='bar', stacked='False',figsize=(10,6))\n",
    "\n",
    "plt.title('Years At Company of Employee')\n",
    "plt.ylabel('Number of Employees')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9676fcf",
   "metadata": {},
   "source": [
    "#### It is observed that the newly arriving employees quit their jobs most,so more concern should be given to the freshers and their cause of leaving the company should be figured out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a4700f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ycr = df.groupby(\"YearsInCurrentRole\")['Attrition'].value_counts(normalize=False).unstack()\n",
    "ysp = df.groupby(\"YearsSinceLastPromotion\")['Attrition'].value_counts(normalize=False).unstack()\n",
    "\n",
    "\n",
    "fig = plt.figure() # create figure\n",
    "\n",
    "ax0 = fig.add_subplot(121) # add subplot 1 (1 row, 2 columns, first plot)\n",
    "ax1 = fig.add_subplot(122) # add subplot 2 (1 row, 2 columns, second plot). See tip below**\n",
    "\n",
    "# Subplot 1: Box plot\n",
    "ycr.plot(kind='bar', stacked='False',figsize=(20,6), ax=ax0) # add to subplot 1\n",
    "ax0.set_title('Same Role')\n",
    "ax0.set_xlabel('Years In Current Role')\n",
    "ax0.set_ylabel('Number of Employees')\n",
    "\n",
    "# Subplot 2: Line plot\n",
    "ysp.plot(kind='bar', stacked='False',figsize=(20,6), ax=ax1) # add to subplot 2\n",
    "ax1.set_title ('Last Promotion')\n",
    "ax1.set_ylabel('Number of Employees')\n",
    "ax1.set_xlabel('Years Since Last Promotion')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb2a781",
   "metadata": {},
   "source": [
    "#### From the above two plots, it is very clear that Employees who are in same post or not getting promoted tend to leave the company most. It is a major concern, since experienced Employees quiting their jobs would affect the company most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78545554",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ycm = df.groupby(\"YearsWithCurrManager\")['Attrition'].value_counts(normalize=False).unstack()\n",
    "\n",
    "ycm.plot(kind='bar', stacked='False',figsize=(10,6))\n",
    "\n",
    "plt.title('Years with Current Manager')\n",
    "plt.ylabel('Number of Employee')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1775ce",
   "metadata": {},
   "source": [
    "#### It is clear that in the starting of relation of Manager and Employee's are not so happy. It is important that the Manager communication with the employee from the starting itself trying to understand them soon to reduce the increase in Attrition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ce3d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "twy = df.groupby(\"TotalWorkingYears\")['Attrition'].value_counts(normalize=False).unstack()\n",
    "\n",
    "twy.plot(kind='bar', stacked='False',figsize=(8,5))\n",
    "\n",
    "plt.title('Total Working Years of Experience')\n",
    "plt.ylabel('Number of Employee')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd37e9e2",
   "metadata": {},
   "source": [
    "#### It is observed that freshers leave the company very likely so it's important that company creates a new policy to handle freshers so they don't leave the company from the start."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a188975b",
   "metadata": {},
   "source": [
    "## Analysis of Monthly Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7310b327",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi = df[df['Attrition']=='Yes']['MonthlyIncome']\n",
    "mi = mi.reset_index()\n",
    "mi.drop(['index'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "mn = df[df['Attrition']=='No']['MonthlyIncome']\n",
    "mn = mn.reset_index()\n",
    "mn.drop(['index'], axis=1, inplace=True)\n",
    "\n",
    "mi['mn'] = mn\n",
    "mi.rename(columns={'MonthlyIncome':'Yes', 'mn':'No'}, inplace=True)\n",
    "mi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f78ab94",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi.plot(kind='box', figsize=(10, 7))\n",
    "\n",
    "plt.title('Box plot of Monthly Income vs Attrition')\n",
    "plt.ylabel('Monthly Income')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d53d036",
   "metadata": {},
   "source": [
    "#### Employees who left their jobs tend to have low average monthly income than those who continued their job in the company."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f0e7ea",
   "metadata": {},
   "source": [
    "## Over Time Employee Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb26c127",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot = df[['OverTime', 'MonthlyIncome', 'Attrition']]\n",
    "oyay = dot[(df['OverTime']=='Yes') & (df['Attrition']=='Yes')]\n",
    "oyay = oyay.sort_values(by = 'MonthlyIncome', ascending=False, axis=0) #sorting to get the top values\n",
    "count, bin_edges = np.histogram(oyay['MonthlyIncome'])\n",
    "\n",
    "oyay.plot(kind='hist', xticks=bin_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874d6adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "oyan = dot[(df['OverTime']=='Yes') & (df['Attrition']=='No')]\n",
    "count, bin_edges = np.histogram(oyan['MonthlyIncome'])\n",
    "\n",
    "oyan.plot(kind='hist', xticks=bin_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d72674e",
   "metadata": {},
   "outputs": [],
   "source": [
    "onay = dot[(df['OverTime']=='No') & (df['Attrition']=='Yes')]\n",
    "count, bin_edges = np.histogram(onay['MonthlyIncome'])\n",
    "\n",
    "onay.plot(kind='hist', xticks=bin_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c988e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "onan = dot[(df['OverTime']=='No') & (df['Attrition']=='No')]\n",
    "count, bin_edges = np.histogram(onan['MonthlyIncome'])\n",
    "\n",
    "onan.plot(kind='hist',alpha =0.4, xticks=bin_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fecfc9",
   "metadata": {},
   "source": [
    "## Analysis on Department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa2d830",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpt = df[['Department','Attrition']]\n",
    "dpt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3b48c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpt['Department'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921db0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpt['Department'].value_counts().plot(kind='pie',\n",
    "                            figsize=(15, 6),\n",
    "                            autopct='%1.1f%%', \n",
    "                            startangle=90,    \n",
    "                            shadow=True,       \n",
    "                            labels=None)   \n",
    "plt.axis('equal') \n",
    "plt.legend(labels=dpt['Department'].unique(), loc='upper left') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87824fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpm = df.groupby(\"Department\")['Attrition'].value_counts(normalize=False).unstack()\n",
    "dpm = dpm.transpose()\n",
    "dpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0164534",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labels = ['Human Resources', 'Research & Development', 'Sales',]\n",
    "sizes = [63, 961, 446]\n",
    "labels_attrition = ['Yes','No','Yes','No','Yes','No']\n",
    "sizes_attrition = [12,51,133,828,92,354]\n",
    "colors = ['#ff6666', '#ffcc99', '#99ff99']\n",
    "\n",
    "colors_attrition = ['#0a0e77','#9e0723', '#0a0e77','#9e0723', '#0a0e77','#9e0723', '#0a0e77','#9e0723']\n",
    " \n",
    "# Plot\n",
    "plt.pie(sizes, autopct='%1.1f%%', pctdistance=.87, labels=labels, colors=colors, startangle=90,frame=True)\n",
    "plt.pie(sizes_attrition,colors=colors_attrition,radius=0.75,startangle=90)\n",
    "centre_circle = plt.Circle((0,0),0.5,color='black', fc='white',linewidth=0.5)\n",
    "fig6 = plt.gcf()\n",
    "fig6.gca().add_artist(centre_circle)\n",
    "\n",
    "#legend\n",
    "import matplotlib.patches as mpatches\n",
    "pur = mpatches.Patch(color='#0a0e77', label='Yes')\n",
    "pin = mpatches.Patch(color='#9e0723', label='No')\n",
    "plt.legend(handles=[pur, pin], loc='upper left')\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446547a6",
   "metadata": {},
   "source": [
    "## Gender Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7425b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "gda = df[['Gender', 'DistanceFromHome', 'Attrition']]\n",
    "gda.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30c9f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "gda['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943218e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gda['Gender'].value_counts().plot(kind='pie',\n",
    "                            figsize=(15, 6),\n",
    "                            autopct='%1.1f%%', \n",
    "                            startangle=90,    \n",
    "                            shadow=True,       \n",
    "                            labels=None)   \n",
    "plt.axis('equal') \n",
    "plt.legend(labels=['Male', 'Female'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3576a4b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fma = gda.groupby(\"Gender\")['Attrition'].value_counts(normalize=False).unstack()\n",
    "fma = fma.transpose()\n",
    "fma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004aa078",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Male', 'Female']\n",
    "sizes = [882,588]\n",
    "labels_attrition = ['Yes','No','Yes','No']\n",
    "sizes_attrition = [150,732,87,501]\n",
    "colors = ['#ff6666', '#ffcc99']\n",
    "\n",
    "colors_attrition = ['#c2c2f0','#ffb3e6', '#c2c2f0','#ffb3e6']\n",
    " \n",
    "# Plot\n",
    "plt.pie(sizes, labels=labels, colors=colors, startangle=90,frame=True)\n",
    "plt.pie(sizes_attrition,colors=colors_attrition,radius=0.75,startangle=90)\n",
    "centre_circle = plt.Circle((0,0),0.5,color='black', fc='white',linewidth=0.5)\n",
    "fig6 = plt.gcf()\n",
    "fig6.gca().add_artist(centre_circle)\n",
    "\n",
    "#legend\n",
    "import matplotlib.patches as mpatches\n",
    "pur = mpatches.Patch(color='#c2c2f0', label='Yes')\n",
    "pin = mpatches.Patch(color='#ffb3e6', label='No')\n",
    "plt.legend(handles=[pur, pin], loc='center')\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf05d63",
   "metadata": {},
   "source": [
    "## Analysis of Marital Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b45aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = df[['MaritalStatus', 'Attrition']]\n",
    "ms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b563e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ms['MaritalStatus'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef56ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms['MaritalStatus'].value_counts().plot(kind='pie',\n",
    "                            figsize=(15, 6),\n",
    "                            autopct='%1.1f%%', \n",
    "                            startangle=90,    \n",
    "                            shadow=True,       \n",
    "                            labels=None)   \n",
    "plt.axis('equal') \n",
    "plt.legend(labels=['Married', 'Single', 'Divorced'], loc='upper left') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bb27e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa = ms.groupby(\"MaritalStatus\")['Attrition'].value_counts(normalize=False).unstack()\n",
    "msa = msa.transpose()\n",
    "msa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53f4874",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = ['Married', 'Single', 'Divorced']\n",
    "sizes = [673, 470, 327]\n",
    "labels_attrition = ['Yes','No','Yes','No','Yes','No']\n",
    "sizes_attrition = [84,589,120,350,33,294]\n",
    "colors = ['#ff6666', '#ffcc99', '#99ff99']\n",
    "\n",
    "colors_attrition = ['#c2c2f0','#ffb3e6', '#c2c2f0','#ffb3e6', '#c2c2f0','#ffb3e6']\n",
    " \n",
    "# Plot\n",
    "plt.pie(sizes, labels=labels, colors=colors, startangle=90,frame=True)\n",
    "plt.pie(sizes_attrition,colors=colors_attrition,radius=0.75,startangle=90)\n",
    "centre_circle = plt.Circle((0,0),0.5,color='black', fc='white',linewidth=0.5)\n",
    "fig6 = plt.gcf()\n",
    "fig6.gca().add_artist(centre_circle)\n",
    "\n",
    "#legend\n",
    "import matplotlib.patches as mpatches\n",
    "pur = mpatches.Patch(color='#c2c2f0', label='Yes')\n",
    "pin = mpatches.Patch(color='#ffb3e6', label='No')\n",
    "plt.legend(handles=[pur, pin], loc='center')\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae22a8ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 20))\n",
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad001bd",
   "metadata": {},
   "source": [
    "## Co-Relation-To check the collinearity of all independent continuous variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c0cc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcb3f31",
   "metadata": {},
   "source": [
    "## Label Encoding- To convert categorical columns into numerical ones so that they can be fitted by machine learning models which only take numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb48820",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4644561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the categorical columns for label encoding\n",
    "categorical_cols = [\"Attrition\",\"BusinessTravel\", \"Department\", \"EducationField\", \"Gender\", \"JobRole\", \"MaritalStatus\", \"OverTime\"]\n",
    "\n",
    "# Perform label encoding on the categorical columns\n",
    "label_encoder = LabelEncoder()\n",
    "for col in categorical_cols:\n",
    "    df[col] = label_encoder.fit_transform(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387a6fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix\n",
    "correlation_matrix = df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691d15f4",
   "metadata": {},
   "source": [
    "## Heatmap-To visualise how well features correlate with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08b0981",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 20))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59033bb7",
   "metadata": {},
   "source": [
    "# To check the datatype and count of non - null values in the data after Label Encoding\n",
    "* For Continuous - int64 ,int32, float\n",
    "* For Categorical - object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce8d022",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d3303e",
   "metadata": {},
   "source": [
    "## Checking top five rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc68e35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1675747c",
   "metadata": {},
   "source": [
    "# Splitting the data into training set and testing set to build and predict the model using Machine Learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d23589b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49455185",
   "metadata": {},
   "source": [
    "### Taking independent variables in X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad639fdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = df.drop(['Attrition'], axis=1)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173c04a8",
   "metadata": {},
   "source": [
    "### Checking all column names in X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60af169",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72c21f7",
   "metadata": {},
   "source": [
    "### Taking target variable in y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5dbea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Attrition']\n",
    "\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e11b4c",
   "metadata": {},
   "source": [
    "### Splitting the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b5d3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08afc9e",
   "metadata": {},
   "source": [
    "### Checking the shape of training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0bda4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479d69c3",
   "metadata": {},
   "source": [
    "# Scaling-To convert data into common range of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b16d6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4650e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075daac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train[['Age', 'BusinessTravel', 'DailyRate', 'Department', 'DistanceFromHome',\n",
    "       'Education', 'EducationField', 'EnvironmentSatisfaction',\n",
    "       'HourlyRate', 'JobInvolvement', 'JobLevel', 'JobRole',\n",
    "       'JobSatisfaction', 'MaritalStatus', 'MonthlyIncome', 'MonthlyRate',\n",
    "       'NumCompaniesWorked', 'PercentSalaryHike',\n",
    "       'PerformanceRating', 'RelationshipSatisfaction',\n",
    "       'TotalWorkingYears', 'TrainingTimesLastYear', 'WorkLifeBalance',\n",
    "       'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion',\n",
    "       'YearsWithCurrManager']] = scaler.fit_transform(X_train[['Age', 'BusinessTravel', 'DailyRate', 'Department', 'DistanceFromHome',\n",
    "       'Education', 'EducationField', 'EnvironmentSatisfaction',\n",
    "       'HourlyRate', 'JobInvolvement', 'JobLevel', 'JobRole',\n",
    "       'JobSatisfaction', 'MaritalStatus', 'MonthlyIncome', 'MonthlyRate',\n",
    "       'NumCompaniesWorked', 'PercentSalaryHike',\n",
    "       'PerformanceRating', 'RelationshipSatisfaction',\n",
    "       'TotalWorkingYears', 'TrainingTimesLastYear', 'WorkLifeBalance',\n",
    "       'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion',\n",
    "       'YearsWithCurrManager']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6752a8",
   "metadata": {},
   "source": [
    "### Checking top row of X-train after scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ea565f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c873ebe0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_test[['Age', 'BusinessTravel', 'DailyRate', 'Department', 'DistanceFromHome',\n",
    "       'Education', 'EducationField', 'EnvironmentSatisfaction',\n",
    "       'HourlyRate', 'JobInvolvement', 'JobLevel', 'JobRole',\n",
    "       'JobSatisfaction', 'MaritalStatus', 'MonthlyIncome', 'MonthlyRate',\n",
    "       'NumCompaniesWorked', 'PercentSalaryHike',\n",
    "       'PerformanceRating', 'RelationshipSatisfaction',\n",
    "       'TotalWorkingYears', 'TrainingTimesLastYear', 'WorkLifeBalance',\n",
    "       'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion',\n",
    "       'YearsWithCurrManager']] = scaler.fit_transform(X_test[['Age', 'BusinessTravel', 'DailyRate', 'Department', 'DistanceFromHome',\n",
    "       'Education', 'EducationField', 'EnvironmentSatisfaction',\n",
    "       'HourlyRate', 'JobInvolvement', 'JobLevel', 'JobRole',\n",
    "       'JobSatisfaction', 'MaritalStatus', 'MonthlyIncome', 'MonthlyRate',\n",
    "       'NumCompaniesWorked', 'PercentSalaryHike',\n",
    "       'PerformanceRating', 'RelationshipSatisfaction',\n",
    "       'TotalWorkingYears', 'TrainingTimesLastYear', 'WorkLifeBalance',\n",
    "       'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion',\n",
    "       'YearsWithCurrManager']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038e5f2b",
   "metadata": {},
   "source": [
    "### Checking top row of X_test after scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0df32b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9983940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b3c60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4569ab56",
   "metadata": {},
   "source": [
    "### Instantiate Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00450a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784af78a",
   "metadata": {},
   "source": [
    "### Training data is used for model building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9085d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8861f3",
   "metadata": {},
   "source": [
    "### Testing data is used for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cbaeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_logreg = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699a3937",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98dc24c",
   "metadata": {},
   "source": [
    "### Calculate accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ff4176",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = accuracy_score(y_test, y_pred_logreg)\n",
    "print(\"Accuracy for logistic regression model is :\", LR,\" and in percentage is :\", LR*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f02fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for Validation of models\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ba39b3",
   "metadata": {},
   "source": [
    "### Create confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bf7b78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logistic_confusion_matrix = confusion_matrix(y_test, y_pred_logreg)\n",
    "logistic_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61675a0c",
   "metadata": {},
   "source": [
    "### Create labels for confusion matrix heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a0a786",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(logistic_confusion_matrix)\n",
    "\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                logistic_confusion_matrix.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     logistic_confusion_matrix.flatten()/np.sum(logistic_confusion_matrix)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "# Create heatmap of confusion matrix\n",
    "sns.heatmap(logistic_confusion_matrix, annot=labels, fmt='', cmap='Greens')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e31eec2",
   "metadata": {},
   "source": [
    "### Function to plot ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfa7e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function For Logistic Regression Create Summary For Logistic Regression\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "def plot_roc_curve(fpr, tpr):\n",
    "    plt.plot(fpr, tpr, color='orange', lw=2,linestyle='--')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle=':')\n",
    "    plt.xlabel('False Positive Rate(1-specificity)')\n",
    "    plt.ylabel('True Positive Rate (sensitivity)')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Function to generate summary for Logistic Regression.\n",
    "\n",
    "def get_summary(y_test, y_pred_logreg):\n",
    "    # Confusion Matrix\n",
    "    conf_mat = confusion_matrix(y_test, y_pred_logreg)\n",
    "    TP = conf_mat[0,0:1]\n",
    "    FP = conf_mat[0,1:2]\n",
    "    FN = conf_mat[1,0:1]\n",
    "    TN = conf_mat[1,1:2]\n",
    "    \n",
    " # Calculate evaluation metrics.\n",
    "\n",
    "    accuracy = (TP+TN)/((FN+FP)+(TP+TN))\n",
    "    sensitivity = TP/(TP+FN)\n",
    "    specificity = TN/(TN+FP)\n",
    "    precision = TP/(TP+FP)\n",
    "    recall =  TP / (TP + FN)\n",
    "    fScore = (2 * recall * precision) / (recall + precision)\n",
    "    auc = roc_auc_score(y_test, y_pred_logreg)\n",
    "\n",
    " # Print summary.\n",
    "\n",
    "    print(\"Confusion Matrix:\\n\",conf_mat)\n",
    "    print(\"Accuracy:\",accuracy)\n",
    "    print(\"Sensitivity :\",sensitivity)\n",
    "    print(\"Specificity :\",specificity)\n",
    "    print(\"Precision:\",precision)\n",
    "    print(\"Recall:\",recall)\n",
    "    print(\"F-score:\",fScore)\n",
    "    print(\"AUC:\",auc)\n",
    "    print(\"ROC curve:\")\n",
    "\n",
    " # Plot ROC curve\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_logreg)\n",
    "    plot_roc_curve(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df53c1b",
   "metadata": {},
   "source": [
    "### Generate summary for logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32af05b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_summary(y_test, y_pred_logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f895f79c",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f4ebe1",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis (EDA) . ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132bdfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the training data\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05424a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the target variable in the training data\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac371be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5094cef4",
   "metadata": {},
   "source": [
    "### Instantiate SVM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d08f634",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102cfa49",
   "metadata": {},
   "source": [
    "### Training the SVM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f48a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bd3610",
   "metadata": {},
   "source": [
    "### Predicting with the SVM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fc5496",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svc = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84aa5633",
   "metadata": {},
   "source": [
    "### Calculate accuracy of the SVM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef060780",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM = accuracy_score(y_test, y_pred_svc)\n",
    "\n",
    "# Print accuracy in percentage\n",
    "print(\"Accuracy for Support Vector Machine model is :\", SVM,\" and in percentage is :\", SVM*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e9bca5",
   "metadata": {},
   "source": [
    "### Create confusion matrix for SVM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9fa7d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SVM_confusion_matrix = confusion_matrix(y_test, y_pred_svc)\n",
    "SVM_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cfb1a1",
   "metadata": {},
   "source": [
    "### Create labels for confusion matrix heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746bdd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(SVM_confusion_matrix)\n",
    "\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                SVM_confusion_matrix.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     SVM_confusion_matrix.flatten()/np.sum(SVM_confusion_matrix)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "# Create heatmap of confusion matrix for SVM model\n",
    "\n",
    "sns.heatmap(SVM_confusion_matrix, annot=labels, fmt='', cmap='Reds')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598c4f7c",
   "metadata": {},
   "source": [
    "### Generate summary for SVM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17c08ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_summary(y_test, y_pred_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7715b4",
   "metadata": {},
   "source": [
    "#### Overall, the code trains an SVM model, predicts with the model, evaluates the model's performance using accuracy and a confusion matrix, generates a summary of evaluation metrics, and displays a heatmap of the confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9b68ca",
   "metadata": {},
   "source": [
    "#  Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d140aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2402127e",
   "metadata": {},
   "source": [
    "### Instantiate Gaussian Naive Bayes model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16102cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefaf1b3",
   "metadata": {},
   "source": [
    "### Training the Naive Bayes model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a7e83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc52f8eb",
   "metadata": {},
   "source": [
    "### Predicting with the Naive Bayes model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec630f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gnb = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965e05ff",
   "metadata": {},
   "source": [
    "### Calculate accuracy of the Naive Bayes model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1613159a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB = accuracy_score(y_test,y_pred_gnb)\n",
    "\n",
    "# Print accuracy in percentage\n",
    "\n",
    "print(\"Accuracy for Naive Bayes model is :\", NB,\" and in percentage is :\", NB*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cfef6c",
   "metadata": {},
   "source": [
    "### Create confusion matrix for Naive Bayes model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94169500",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_confusion_matrix = confusion_matrix(y_test, y_pred_gnb)\n",
    "gnb_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470f7ace",
   "metadata": {},
   "source": [
    "### Create labels for confusion matrix heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c83e6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gnb_confusion_matrix)\n",
    "\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                gnb_confusion_matrix.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     gnb_confusion_matrix.flatten()/np.sum(gnb_confusion_matrix)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "# Create heatmap of confusion matrix for Naive Bayes model\n",
    "\n",
    "sns.heatmap(gnb_confusion_matrix, annot=labels, fmt='', cmap='icefire')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6ba31c",
   "metadata": {},
   "source": [
    "### Generate summary for Naive Bayes model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c000cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_summary(y_test, y_pred_gnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba41508",
   "metadata": {},
   "source": [
    "#### Overall, the code trains a Naive Bayes model, predicts with the model, evaluates the model's performance using accuracy and a confusion matrix, generates a summary of evaluation metrics, and displays a heatmap."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85eebfbe",
   "metadata": {},
   "source": [
    "#  K-Nearest Neighbors (KNN) Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2254ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dc6697",
   "metadata": {},
   "source": [
    "### Instantiate KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301c051f",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803b5283",
   "metadata": {},
   "source": [
    "### Training the KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e498831d",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbf3d79",
   "metadata": {},
   "source": [
    "### Predicting with the KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d245dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_knn = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e783da",
   "metadata": {},
   "source": [
    "### Calculate accuracy of the KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0022ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = accuracy_score(y_test, y_pred_knn)\n",
    "\n",
    "\n",
    "# Print accuracy in percentage\n",
    "\n",
    "print(\"Accuracy for K nerarest neighbour model is :\", KNN,\" and in percentage is :\", KNN*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ecf430",
   "metadata": {},
   "source": [
    "### Create confusion matrix for KNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363fd707",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "knn_confusion_matrix = confusion_matrix(y_test, y_pred_knn)\n",
    "knn_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c718815",
   "metadata": {},
   "source": [
    "### Create labels for confusion matrix heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b439e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(knn_confusion_matrix)\n",
    "\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "               knn_confusion_matrix.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     knn_confusion_matrix.flatten()/np.sum(knn_confusion_matrix)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "# Create heatmap of confusion matrix for KNN model\n",
    "\n",
    "sns.heatmap(knn_confusion_matrix, annot=labels, fmt='', cmap='coolwarm')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1fffae",
   "metadata": {},
   "source": [
    "### Generate summary for KNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9584e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_summary(y_test, y_pred_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765c39d4",
   "metadata": {},
   "source": [
    "#### Overall, the code trains a KNN model, predicts with the model, evaluates the model's performance using accuracy and a confusion matrix, generates a summary of evaluation metrics, and displays a heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1d90b6",
   "metadata": {},
   "source": [
    "# Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925f388c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8e5550",
   "metadata": {},
   "source": [
    "### Instantiate Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d548ea26",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a97b0bd",
   "metadata": {},
   "source": [
    "### Training the Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c78f41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1673078",
   "metadata": {},
   "source": [
    "### Predicting with the Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ea4775",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dtree = dtree.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc6577b",
   "metadata": {},
   "source": [
    "### Calculate accuracy of the Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5eb6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = accuracy_score(y_test, y_pred_dtree) \n",
    "\n",
    "# Print accuracy in percentage\n",
    "\n",
    "print(\"Accuracy for decision tree model is :\", DT,\" and in percentage is :\", DT*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf7248f",
   "metadata": {},
   "source": [
    "### Create confusion matrix for Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344a3471",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree_confusion_matrix = confusion_matrix(y_test, y_pred_dtree)\n",
    "dtree_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584c49a6",
   "metadata": {},
   "source": [
    "### Create labels for confusion matrix heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9e0dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dtree_confusion_matrix)\n",
    "\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "               dtree_confusion_matrix.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     dtree_confusion_matrix.flatten()/np.sum(dtree_confusion_matrix)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "\n",
    "# Create heatmap of confusion matrix for Decision Tree model\n",
    "\n",
    "sns.heatmap(dtree_confusion_matrix, annot=labels, fmt='', cmap='Spectral')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58be7a47",
   "metadata": {},
   "source": [
    "### Generate summary for Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744d37c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_summary(y_test, y_pred_dtree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a166cb9",
   "metadata": {},
   "source": [
    "#### Overall, the code trains a Decision Tree model, predicts with the model, evaluates its performance using accuracy and a confusion matrix, generates a summary of evaluation metrics, and displays a heatmap."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5057e0c2",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43ece09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21699677",
   "metadata": {},
   "source": [
    "### Instantiate Random Forest Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9497bc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209863f7",
   "metadata": {},
   "source": [
    "### Training the Random Forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62747ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a29d80c",
   "metadata": {},
   "source": [
    "### Predicting with the Random Forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd2b622",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfc = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9902f6f",
   "metadata": {},
   "source": [
    "### Calculate accuracy of the Random Forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8523656",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = accuracy_score(y_test, y_pred_rfc)\n",
    "\n",
    "# Print accuracy in percentage\n",
    "print(\"Accuracy random forest model is :\", RF,\" and in percentage is :\", RF*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93086da1",
   "metadata": {},
   "source": [
    "### Create confusion matrix for Random Forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ebf9d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RandomForest_confusion_matrix = confusion_matrix(y_test, y_pred_rfc)\n",
    "RandomForest_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a48d71",
   "metadata": {},
   "source": [
    "### Create labels for confusion matrix heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8846d2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(RandomForest_confusion_matrix)\n",
    "\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                RandomForest_confusion_matrix.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     RandomForest_confusion_matrix.flatten()/np.sum(RandomForest_confusion_matrix)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "# Create heatmap of confusion matrix for Random Forest model\n",
    "\n",
    "sns.heatmap(RandomForest_confusion_matrix, annot=labels, fmt='', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c37bdb",
   "metadata": {},
   "source": [
    "### Generate summary for Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d301e6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get_summary(y_test, y_pred_rfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f29d242",
   "metadata": {},
   "source": [
    "#### Overall, the code trains a Random Forest model, predicts with the model, evaluates its performance using accuracy and a confusion matrix, generates a summary of evaluation metrics, and displays a heatmap."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee410afc",
   "metadata": {},
   "source": [
    "### Accuracy scores summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd12ee13",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = accuracy_score(y_test, y_pred_logreg)\n",
    "SVM = accuracy_score(y_test, y_pred_svc)\n",
    "NB = accuracy_score(y_test,y_pred_gnb)\n",
    "KNN = accuracy_score(y_test, y_pred_knn)\n",
    "DT = accuracy_score(y_test, y_pred_dtree) \n",
    "RF = accuracy_score(y_test, y_pred_rfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028a1005",
   "metadata": {},
   "source": [
    "### Create a bar chart to compare the accuracy of all classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b04ffb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = ['LR','SVM','NB','KNN','DT', 'RF']\n",
    "accuracies = [LR,SVM,NB,KNN,DT,RF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89666560",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "c = ['red', 'yellow', 'pink', 'blue', 'orange','green']\n",
    "plt.bar(algorithms, accuracies,color=c)\n",
    "plt.xlabel('Algorithm')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Comparison of Classifier Accuracy')\n",
    "plt.ylim([0, 1])  # Set the y-axis limits between 0 and 1 or 0 and 100. \n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "for i in range(len(algorithms)):\n",
    "    plt.text(i, accuracies[i],f\"{accuracies[i]*100:.2f}%\", ha='center',va= 'bottom')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd97251",
   "metadata": {},
   "source": [
    "##### This visualization provides a comparison of the accuracy of different classification models, allowing you to easily identify the model with the highest accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e336ab",
   "metadata": {},
   "source": [
    "# Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820ccaa9",
   "metadata": {},
   "source": [
    "## The below recommendations is based on the key findings related to reducing attrition rate.\n",
    "### 1. Age:\n",
    "#### - Implement strategies to address the specific needs and career aspirations of employees across different age groups. - This can include offering targeted development opportunities, mentorship programs, and flexible work arrangements to support work-life balance.\n",
    "### 2. Compensation:\n",
    "#### - Regularly review and benchmark compensation packages to ensure they are competitive in the market.\n",
    "#### - Consider incorporating performance-based incentives and rewards to motivate employees and recognize their contributions.\n",
    "### 3. Job experience:\n",
    "#### - Provide opportunities for career advancement, skill development, and cross-functional training.\n",
    "#### - Establish clear career paths and provide regular feedback and performance evaluations to support employee growth and engagement.\n",
    "### 4. Specific job-related variables: - Tailor retention strategies based on different job roles and responsibilities.\n",
    "#### - This can include improving job satisfaction, providing challenging assignments, and fostering a positive work environment. 5. Job-related aspects:\n",
    "#### - Enhance employee engagement and job satisfaction by offering a supportive work environment.\n",
    "#### - Provide opportunities for professional development, promote a culture of continuous learning, and ensure fair and transparent processes for promotions and career growth.\n",
    "### 6. Work-related factors:\n",
    "#### - Focus on improving factors such as environment satisfaction, job involvement, job satisfaction, work-life balance, and managing overtime demands.\n",
    "#### - Conduct regular employee surveys to understand their concerns and feedback, and take proactive measures to address any identified areas of improvement.\n",
    "### 7. Overall:\n",
    "#### - Foster a positive organizational culture that values employee well-being, work-life balance, and growth opportunities.\n",
    "#### - Encourage open communication, provide avenues for feedback and suggestions, and regularly evaluate and refine retention strategies based on employee feedback and changing needs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648f0712",
   "metadata": {},
   "source": [
    "# Conclusion :-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff6174c",
   "metadata": {},
   "source": [
    "#### LOGISTIC REGRESSION model has the highest accuracy as compared to other algorithms like SUPPORT VECTOR MACHINE, NAIVE BAYES, K NEAREST NEIGHBOUR, DECISION TREE & RANDOM FOREST. This model is best suited to Predict Or Analyse Employee Attrition. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
